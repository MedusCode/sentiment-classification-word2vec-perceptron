{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "*Nikita Anreev* | *AI534* | *11/19/2024*\n",
    "\n",
    "# HW4: Deep Learning for Sentiment Classification\n",
    "\n",
    "## Preparation"
   ],
   "id": "780a57ac552f16b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:18.885989Z",
     "start_time": "2024-12-03T06:50:18.883356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter"
   ],
   "id": "5407f6425f7225de",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:18.933147Z",
     "start_time": "2024-12-03T06:50:18.915582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dev_data = pd.read_csv('./dev.csv')\n",
    "train_data = pd.read_csv('./train.csv')\n",
    "test_data = pd.read_csv('./test.csv')"
   ],
   "id": "5d77863390ea3922",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:18.942688Z",
     "start_time": "2024-12-03T06:50:18.936256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_embeddings(data, word_vectors):\n",
    "    embeddings = np.zeros((len(data), word_vectors.vector_size))\n",
    "\n",
    "    for i, sentence in enumerate(data['sentence']):\n",
    "        words = sentence.split()\n",
    "        valid_vectors = [word_vectors[word] for word in words if word in word_vectors]\n",
    "\n",
    "        if valid_vectors:\n",
    "            embeddings[i] = np.mean(valid_vectors, axis=0)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def get_embeddings_pruned(data, word_vectors, n):\n",
    "    words = [word for sentence in data['sentence'] for word in sentence.split()]\n",
    "    words_freq = Counter(words)\n",
    "    pruned_words = {word for word, freq in words_freq.items() if freq > n}\n",
    "\n",
    "    embeddings = np.zeros((len(data), word_vectors.vector_size))\n",
    "\n",
    "    for i, sentence in enumerate(data['sentence']):\n",
    "        words = sentence.split()\n",
    "        valid_vectors = [word_vectors[word] for word in words if word in word_vectors and word in pruned_words]\n",
    "\n",
    "        if valid_vectors:\n",
    "            embeddings[i] = np.mean(valid_vectors, axis=0)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def get_one_hot_ids(data):\n",
    "    one_hot_ids = {}\n",
    "    id = 0\n",
    "\n",
    "    for dataset in data:\n",
    "        for sentence in dataset['sentence']:\n",
    "            for word in sentence.split(' '):\n",
    "                if word not in one_hot_ids:\n",
    "                    one_hot_ids[word] = id\n",
    "                    id += 1\n",
    "\n",
    "    return one_hot_ids\n",
    "\n",
    "def get_one_hot(data, ids):\n",
    "    one_hot = np.zeros((len(data), len(ids)))\n",
    "    for i, sentence in enumerate(data['sentence']):\n",
    "        for word in sentence.split(' '):\n",
    "            if word not in ids:\n",
    "                continue\n",
    "\n",
    "            one_hot[i][ids[word]] += 1\n",
    "\n",
    "    return one_hot\n",
    "\n",
    "def train(X_train, y_train, X_dev, y_dev):\n",
    "    best_model = None\n",
    "    best_rate = (0, 101)\n",
    "\n",
    "    for k in range(1, 101, 2):\n",
    "        classifier = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "        model = classifier.fit(X_train, y_train)\n",
    "\n",
    "        predictions = model.predict(X_train)\n",
    "        train_error_rate = (1 - accuracy_score(y_train, predictions)) * 100\n",
    "        train_positive_rate = np.mean(predictions == \"+\") * 100\n",
    "\n",
    "        predictions = model.predict(X_dev)\n",
    "        dev_error_rate = (1 - accuracy_score(y_dev, predictions)) * 100\n",
    "        dev_positive_rate = np.mean(predictions == \"+\") * 100\n",
    "\n",
    "        if dev_error_rate < best_rate[1]:\n",
    "            best_model = model\n",
    "            best_rate = (k, dev_error_rate)\n",
    "\n",
    "        print(f\"k={k}   train_err {train_error_rate:.1f}% (+: {train_positive_rate:.1f}%)   dev_err {dev_error_rate:.1f}% (+: {dev_positive_rate:.1f}%)\")\n",
    "\n",
    "    print(f\"\\nBest dev error rate is {best_rate[1]:.1f}, when k = {best_rate[0]}\")\n",
    "\n",
    "    return best_model"
   ],
   "id": "9552bf2eadc312aa",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1 Word Embeddings\n",
    "### 1.1 Load and Query\n"
   ],
   "id": "63f1425a5f8b4fdd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:18.962855Z",
     "start_time": "2024-12-03T06:50:18.961237Z"
    }
   },
   "cell_type": "code",
   "source": "from gensim.models import KeyedVectors",
   "id": "e11b47d043940322",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:18.990611Z",
     "start_time": "2024-12-03T06:50:18.980611Z"
    }
   },
   "cell_type": "code",
   "source": "wv = KeyedVectors.load('embs_train.kv')",
   "id": "ac957ac5f28d0082",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.2 Vector Similarity",
   "id": "217fb1937ebabe0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:19.024920Z",
     "start_time": "2024-12-03T06:50:19.010627Z"
    }
   },
   "cell_type": "code",
   "source": "wv.most_similar('wonderful', topn=10)",
   "id": "3f6b9c1b4515278e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('marvelous', 0.8188857436180115),\n",
       " ('fantastic', 0.8047919869422913),\n",
       " ('great', 0.7647868990898132),\n",
       " ('fabulous', 0.7614760398864746),\n",
       " ('terrific', 0.7420831918716431),\n",
       " ('lovely', 0.7320095896720886),\n",
       " ('amazing', 0.7263179421424866),\n",
       " ('beautiful', 0.6854085922241211),\n",
       " ('magnificent', 0.6633867025375366),\n",
       " ('delightful', 0.6574996113777161)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:19.121280Z",
     "start_time": "2024-12-03T06:50:19.107160Z"
    }
   },
   "cell_type": "code",
   "source": "wv.most_similar('awful', topn=10)",
   "id": "b3393a59f8ccea87",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('horrible', 0.7597667574882507),\n",
       " ('terrible', 0.7478911280632019),\n",
       " ('dreadful', 0.7218177318572998),\n",
       " ('horrid', 0.6720177531242371),\n",
       " ('atrocious', 0.6626645922660828),\n",
       " ('ugly', 0.6236302852630615),\n",
       " ('lousy', 0.6135216951370239),\n",
       " ('unbelievable', 0.6068726181983948),\n",
       " ('appalling', 0.6061566472053528),\n",
       " ('hideous', 0.5811460614204407)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:19.158242Z",
     "start_time": "2024-12-03T06:50:19.149948Z"
    }
   },
   "cell_type": "code",
   "source": "wv.most_similar('ai', topn=10)",
   "id": "5f0e3d239b066e45",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('te', 0.6197360754013062),\n",
       " ('mai', 0.5895475149154663),\n",
       " ('di', 0.561583399772644),\n",
       " ('cosa', 0.5554686784744263),\n",
       " ('sua', 0.5469498038291931),\n",
       " ('ga', 0.53242027759552),\n",
       " ('se', 0.529657244682312),\n",
       " ('sia', 0.5292683839797974),\n",
       " ('han', 0.5262174010276794),\n",
       " ('uma', 0.5229132175445557)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:19.203824Z",
     "start_time": "2024-12-03T06:50:19.192314Z"
    }
   },
   "cell_type": "code",
   "source": "wv.most_similar('artificial', topn=10)",
   "id": "594226d137472982",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('synthetic', 0.48184075951576233),\n",
       " ('unnatural', 0.431232213973999),\n",
       " ('illusion', 0.4310288727283478),\n",
       " ('sterile', 0.3774666488170624),\n",
       " ('plastic', 0.36900731921195984),\n",
       " ('imaginary', 0.36322855949401855),\n",
       " ('prosthetic', 0.3631141483783722),\n",
       " ('artificiality', 0.3588675856590271),\n",
       " ('natural', 0.33741024136543274),\n",
       " ('stimulation', 0.3294525444507599)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:19.274707Z",
     "start_time": "2024-12-03T06:50:19.265622Z"
    }
   },
   "cell_type": "code",
   "source": "wv.most_similar('life', topn=10)",
   "id": "fae43d0103860013",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lives', 0.6027060151100159),\n",
       " ('lifestyle', 0.44911324977874756),\n",
       " ('lifetime', 0.42942190170288086),\n",
       " ('living', 0.4151720702648163),\n",
       " ('family', 0.41159167885780334),\n",
       " ('everyday', 0.40794867277145386),\n",
       " ('humanity', 0.40773284435272217),\n",
       " ('childhood', 0.4068482220172882),\n",
       " ('society', 0.4066685140132904),\n",
       " ('motherhood', 0.4046342372894287)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.3 Word Analogy",
   "id": "bb82072cd5958566"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:19.301020Z",
     "start_time": "2024-12-03T06:50:19.286474Z"
    }
   },
   "cell_type": "code",
   "source": "wv.most_similar(positive=['sister', 'man'], negative=['woman'], topn=10)",
   "id": "b267b467d77f68d7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('brother', 0.7966989874839783),\n",
       " ('uncle', 0.6753759980201721),\n",
       " ('nephew', 0.6596081852912903),\n",
       " ('son', 0.6472460031509399),\n",
       " ('father', 0.6398823857307434),\n",
       " ('brothers', 0.6266913414001465),\n",
       " ('dad', 0.5981076955795288),\n",
       " ('siblings', 0.5654128789901733),\n",
       " ('daughter', 0.5610913634300232),\n",
       " ('sons', 0.5580724477767944)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:19.346526Z",
     "start_time": "2024-12-03T06:50:19.335744Z"
    }
   },
   "cell_type": "code",
   "source": "wv.most_similar(positive=['harder', 'fast'], negative=['hard'], topn=10)",
   "id": "67365ef5bd442240",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('faster', 0.7064899206161499),\n",
       " ('rapidly', 0.5021132826805115),\n",
       " ('easier', 0.48843100666999817),\n",
       " ('slow', 0.4575234651565552),\n",
       " ('quickly', 0.4370786249637604),\n",
       " ('bigger', 0.4148872196674347),\n",
       " ('cheaper', 0.41006121039390564),\n",
       " ('louder', 0.409576416015625),\n",
       " ('slowly', 0.40936195850372314),\n",
       " ('smarter', 0.40232229232788086)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:19.391527Z",
     "start_time": "2024-12-03T06:50:19.378575Z"
    }
   },
   "cell_type": "code",
   "source": "wv.most_similar(positive=['breathe', 'death'], negative=['life'], topn=5)",
   "id": "5b0f8482617a3061",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('suffocation', 0.4820758104324341),\n",
       " ('suffocated', 0.46953943371772766),\n",
       " ('suffocate', 0.4326365888118744),\n",
       " ('breathing', 0.4223504066467285),\n",
       " ('drowning', 0.3890712857246399)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:19.438458Z",
     "start_time": "2024-12-03T06:50:19.427277Z"
    }
   },
   "cell_type": "code",
   "source": "wv.most_similar(positive=['speed', 'snail'], negative=['horse'], topn=5)",
   "id": "87ab8cca4dec2246",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('speeds', 0.5445727705955505),\n",
       " ('slow', 0.4046669900417328),\n",
       " ('slowness', 0.36570635437965393),\n",
       " ('speedy', 0.36554884910583496),\n",
       " ('faster', 0.3575904071331024)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:19.482570Z",
     "start_time": "2024-12-03T06:50:19.473400Z"
    }
   },
   "cell_type": "code",
   "source": "wv.most_similar(positive=['army', 'gangster'], negative=['soldier'], topn=5)",
   "id": "76c0284847addd8b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mafia', 0.571354866027832),\n",
       " ('underworld', 0.5466997027397156),\n",
       " ('mob', 0.497639536857605),\n",
       " ('gangs', 0.4962001144886017),\n",
       " ('gang', 0.4387965500354767)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2 Better Perceptron using Embeddings",
   "id": "96e44b283871e291"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:19.809604Z",
     "start_time": "2024-12-03T06:50:19.517828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_native_model = None\n",
    "best_one_hot_model = None\n",
    "train_embeddings = get_embeddings(train_data, wv)\n",
    "dev_embeddings = get_embeddings(dev_data, wv)"
   ],
   "id": "3ef7da46f1ad3b04",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.1 Sentence Embedding and k-NN\n",
    "#### 2.1.1"
   ],
   "id": "d65ad40dba614cd8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:19.836892Z",
     "start_time": "2024-12-03T06:50:19.828198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "distances = np.linalg.norm(train_embeddings - train_embeddings[0], axis=1)\n",
    "distances[0] = np.inf\n",
    "\n",
    "train_data.iloc[[0, np.argmin(distances)]]"
   ],
   "id": "2c4c9d00a95a3825",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        id  \\\n",
       "0        0   \n",
       "2061  2061   \n",
       "\n",
       "                                                                                                                                                                                 sentence  \\\n",
       "0                                                                             it 's a tour de force , written and directed so quietly that it 's implosion rather than explosion you fear   \n",
       "2061  a semi autobiographical film that 's so sloppily written and cast that you can not believe anyone more central to the creation of bugsy than the caterer had anything to do with it   \n",
       "\n",
       "     target  \n",
       "0         +  \n",
       "2061      -  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>it 's a tour de force , written and directed so quietly that it 's implosion rather than explosion you fear</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>2061</td>\n",
       "      <td>a semi autobiographical film that 's so sloppily written and cast that you can not believe anyone more central to the creation of bugsy than the caterer had anything to do with it</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.1.2",
   "id": "72cfef245383c0bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:19.885503Z",
     "start_time": "2024-12-03T06:50:19.876148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "distances = np.linalg.norm(train_embeddings - train_embeddings[1], axis=1)\n",
    "distances[1] = np.inf\n",
    "\n",
    "train_data.iloc[[1, np.argmin(distances)]]"
   ],
   "id": "287c6b54ab2413a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        id  \\\n",
       "1        1   \n",
       "4205  4205   \n",
       "\n",
       "                                                                                                                                                                                  sentence  \\\n",
       "1                         places a slightly believable love triangle in a difficult to swallow setting , and then disappointingly moves the story into the realm of an improbable thriller   \n",
       "4205  the plan to make enough into an inspiring tale of survival wrapped in the heart pounding suspense of a stylish psychological thriller ' has flopped as surely as a souffl gone wrong   \n",
       "\n",
       "     target  \n",
       "1         -  \n",
       "4205      -  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>places a slightly believable love triangle in a difficult to swallow setting , and then disappointingly moves the story into the realm of an improbable thriller</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>4205</td>\n",
       "      <td>the plan to make enough into an inspiring tale of survival wrapped in the heart pounding suspense of a stylish psychological thriller ' has flopped as surely as a souffl gone wrong</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.1.3",
   "id": "37dbc90c8207e9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:41.374344Z",
     "start_time": "2024-12-03T06:50:19.932699Z"
    }
   },
   "cell_type": "code",
   "source": "best_native_model = train(train_embeddings, train_data['target'], dev_embeddings, dev_data['target'])",
   "id": "45179adcb19eb5e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1   train_err 0.0% (+: 50.0%)   dev_err 37.0% (+: 52.2%)\n",
      "k=3   train_err 16.1% (+: 50.5%)   dev_err 34.8% (+: 50.0%)\n",
      "k=5   train_err 19.8% (+: 50.0%)   dev_err 34.5% (+: 48.3%)\n",
      "k=7   train_err 21.2% (+: 49.9%)   dev_err 33.8% (+: 49.0%)\n",
      "k=9   train_err 22.0% (+: 49.4%)   dev_err 31.9% (+: 49.1%)\n",
      "k=11   train_err 22.5% (+: 49.3%)   dev_err 30.7% (+: 49.1%)\n",
      "k=13   train_err 22.8% (+: 49.1%)   dev_err 31.3% (+: 48.9%)\n",
      "k=15   train_err 23.6% (+: 49.0%)   dev_err 30.2% (+: 49.6%)\n",
      "k=17   train_err 23.5% (+: 48.9%)   dev_err 31.3% (+: 47.5%)\n",
      "k=19   train_err 23.6% (+: 48.1%)   dev_err 30.9% (+: 47.7%)\n",
      "k=21   train_err 24.0% (+: 48.0%)   dev_err 30.9% (+: 47.5%)\n",
      "k=23   train_err 24.1% (+: 48.1%)   dev_err 31.2% (+: 46.6%)\n",
      "k=25   train_err 24.0% (+: 47.9%)   dev_err 30.2% (+: 45.8%)\n",
      "k=27   train_err 24.4% (+: 47.7%)   dev_err 30.4% (+: 46.0%)\n",
      "k=29   train_err 24.3% (+: 47.6%)   dev_err 29.3% (+: 46.5%)\n",
      "k=31   train_err 24.3% (+: 47.3%)   dev_err 29.6% (+: 46.6%)\n",
      "k=33   train_err 24.3% (+: 46.8%)   dev_err 30.5% (+: 45.9%)\n",
      "k=35   train_err 24.6% (+: 46.6%)   dev_err 29.7% (+: 46.3%)\n",
      "k=37   train_err 24.6% (+: 46.4%)   dev_err 30.0% (+: 46.6%)\n",
      "k=39   train_err 24.8% (+: 46.1%)   dev_err 30.0% (+: 46.8%)\n",
      "k=41   train_err 24.8% (+: 46.3%)   dev_err 30.4% (+: 46.6%)\n",
      "k=43   train_err 24.9% (+: 46.3%)   dev_err 29.7% (+: 46.9%)\n",
      "k=45   train_err 24.6% (+: 46.0%)   dev_err 29.3% (+: 47.5%)\n",
      "k=47   train_err 24.8% (+: 46.1%)   dev_err 29.3% (+: 46.3%)\n",
      "k=49   train_err 25.2% (+: 46.0%)   dev_err 29.1% (+: 46.1%)\n",
      "k=51   train_err 24.9% (+: 46.0%)   dev_err 28.9% (+: 45.7%)\n",
      "k=53   train_err 25.0% (+: 46.0%)   dev_err 29.1% (+: 45.9%)\n",
      "k=55   train_err 25.0% (+: 45.9%)   dev_err 29.2% (+: 45.2%)\n",
      "k=57   train_err 24.8% (+: 45.9%)   dev_err 29.3% (+: 45.3%)\n",
      "k=59   train_err 25.1% (+: 45.8%)   dev_err 29.7% (+: 45.5%)\n",
      "k=61   train_err 24.8% (+: 45.6%)   dev_err 28.5% (+: 45.5%)\n",
      "k=63   train_err 25.0% (+: 45.4%)   dev_err 28.3% (+: 45.3%)\n",
      "k=65   train_err 25.1% (+: 45.2%)   dev_err 28.3% (+: 45.3%)\n",
      "k=67   train_err 25.3% (+: 44.9%)   dev_err 28.0% (+: 45.4%)\n",
      "k=69   train_err 25.1% (+: 44.9%)   dev_err 28.6% (+: 45.6%)\n",
      "k=71   train_err 25.2% (+: 45.0%)   dev_err 28.9% (+: 44.9%)\n",
      "k=73   train_err 25.2% (+: 44.7%)   dev_err 27.8% (+: 45.6%)\n",
      "k=75   train_err 25.3% (+: 44.6%)   dev_err 28.9% (+: 45.1%)\n",
      "k=77   train_err 25.5% (+: 44.9%)   dev_err 28.7% (+: 44.7%)\n",
      "k=79   train_err 25.3% (+: 44.8%)   dev_err 28.7% (+: 45.5%)\n",
      "k=81   train_err 25.1% (+: 44.5%)   dev_err 29.0% (+: 45.2%)\n",
      "k=83   train_err 25.1% (+: 44.4%)   dev_err 28.6% (+: 44.8%)\n",
      "k=85   train_err 25.2% (+: 44.2%)   dev_err 28.9% (+: 44.7%)\n",
      "k=87   train_err 25.2% (+: 44.2%)   dev_err 28.1% (+: 44.5%)\n",
      "k=89   train_err 25.3% (+: 44.4%)   dev_err 28.4% (+: 44.8%)\n",
      "k=91   train_err 25.3% (+: 44.4%)   dev_err 28.8% (+: 44.4%)\n",
      "k=93   train_err 25.3% (+: 44.3%)   dev_err 29.2% (+: 43.8%)\n",
      "k=95   train_err 25.3% (+: 44.3%)   dev_err 29.1% (+: 43.3%)\n",
      "k=97   train_err 25.3% (+: 44.5%)   dev_err 29.4% (+: 43.4%)\n",
      "k=99   train_err 25.4% (+: 44.1%)   dev_err 28.7% (+: 43.5%)\n",
      "\n",
      "Best dev error rate is 27.8, when k = 73\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.1.4",
   "id": "216ac094adca15f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:58:19.778951Z",
     "start_time": "2024-12-03T06:50:41.398320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "one_hot_ids = get_one_hot_ids([train_data, dev_data])\n",
    "train_one_hot = get_one_hot(train_data, one_hot_ids)\n",
    "dev_one_hot = get_one_hot(dev_data, one_hot_ids)\n",
    "\n",
    "best_one_hot_model = train(train_one_hot, train_data['target'], dev_one_hot, dev_data['target'])"
   ],
   "id": "97f9cfc7572aa86d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1   train_err 0.0% (+: 50.0%)   dev_err 42.8% (+: 46.8%)\n",
      "k=3   train_err 22.5% (+: 48.0%)   dev_err 41.4% (+: 47.0%)\n",
      "k=5   train_err 27.1% (+: 46.5%)   dev_err 41.8% (+: 45.8%)\n",
      "k=7   train_err 30.8% (+: 46.7%)   dev_err 40.6% (+: 46.8%)\n",
      "k=9   train_err 31.3% (+: 47.1%)   dev_err 40.3% (+: 49.1%)\n",
      "k=11   train_err 32.3% (+: 48.3%)   dev_err 41.8% (+: 49.2%)\n",
      "k=13   train_err 33.4% (+: 49.2%)   dev_err 41.7% (+: 50.7%)\n",
      "k=15   train_err 33.7% (+: 51.0%)   dev_err 42.9% (+: 51.7%)\n",
      "k=17   train_err 34.3% (+: 52.1%)   dev_err 42.9% (+: 54.1%)\n",
      "k=19   train_err 34.5% (+: 52.6%)   dev_err 42.6% (+: 54.6%)\n",
      "k=21   train_err 34.9% (+: 54.4%)   dev_err 43.0% (+: 57.6%)\n",
      "k=23   train_err 35.0% (+: 55.1%)   dev_err 43.1% (+: 58.5%)\n",
      "k=25   train_err 36.3% (+: 55.0%)   dev_err 43.5% (+: 57.1%)\n",
      "k=27   train_err 36.2% (+: 55.7%)   dev_err 43.3% (+: 57.9%)\n",
      "k=29   train_err 35.9% (+: 56.2%)   dev_err 42.2% (+: 59.0%)\n",
      "k=31   train_err 35.9% (+: 57.3%)   dev_err 43.0% (+: 59.4%)\n",
      "k=33   train_err 36.0% (+: 59.1%)   dev_err 42.9% (+: 61.7%)\n",
      "k=35   train_err 36.9% (+: 58.8%)   dev_err 43.5% (+: 60.9%)\n",
      "k=37   train_err 36.8% (+: 60.0%)   dev_err 43.4% (+: 62.4%)\n",
      "k=39   train_err 36.6% (+: 60.2%)   dev_err 43.6% (+: 62.2%)\n",
      "k=41   train_err 36.9% (+: 59.5%)   dev_err 43.9% (+: 62.1%)\n",
      "k=43   train_err 37.4% (+: 60.3%)   dev_err 43.8% (+: 61.8%)\n",
      "k=45   train_err 37.4% (+: 59.8%)   dev_err 43.6% (+: 61.8%)\n",
      "k=47   train_err 37.0% (+: 59.7%)   dev_err 42.2% (+: 60.2%)\n",
      "k=49   train_err 37.5% (+: 61.9%)   dev_err 43.8% (+: 63.0%)\n",
      "k=51   train_err 37.9% (+: 61.9%)   dev_err 43.1% (+: 64.9%)\n",
      "k=53   train_err 37.6% (+: 62.6%)   dev_err 44.2% (+: 64.8%)\n",
      "k=55   train_err 37.8% (+: 62.7%)   dev_err 44.2% (+: 64.0%)\n",
      "k=57   train_err 38.1% (+: 63.0%)   dev_err 43.9% (+: 63.9%)\n",
      "k=59   train_err 38.3% (+: 63.2%)   dev_err 44.8% (+: 64.4%)\n",
      "k=61   train_err 38.3% (+: 63.4%)   dev_err 43.2% (+: 64.2%)\n",
      "k=63   train_err 38.8% (+: 64.3%)   dev_err 43.5% (+: 64.5%)\n",
      "k=65   train_err 39.0% (+: 64.4%)   dev_err 43.6% (+: 64.4%)\n",
      "k=67   train_err 38.8% (+: 64.6%)   dev_err 44.7% (+: 64.7%)\n",
      "k=69   train_err 39.2% (+: 65.4%)   dev_err 44.5% (+: 66.1%)\n",
      "k=71   train_err 39.2% (+: 65.8%)   dev_err 44.0% (+: 66.4%)\n",
      "k=73   train_err 39.0% (+: 64.4%)   dev_err 43.6% (+: 65.2%)\n",
      "k=75   train_err 39.3% (+: 65.3%)   dev_err 44.3% (+: 66.7%)\n",
      "k=77   train_err 39.2% (+: 64.8%)   dev_err 42.7% (+: 65.5%)\n",
      "k=79   train_err 39.2% (+: 65.3%)   dev_err 42.7% (+: 66.3%)\n",
      "k=81   train_err 39.7% (+: 65.3%)   dev_err 43.8% (+: 67.2%)\n",
      "k=83   train_err 39.5% (+: 66.4%)   dev_err 43.9% (+: 67.3%)\n",
      "k=85   train_err 39.6% (+: 66.7%)   dev_err 45.1% (+: 67.7%)\n",
      "k=87   train_err 39.5% (+: 66.0%)   dev_err 45.0% (+: 66.4%)\n",
      "k=89   train_err 39.7% (+: 67.0%)   dev_err 44.8% (+: 67.4%)\n",
      "k=91   train_err 39.4% (+: 66.7%)   dev_err 43.9% (+: 67.9%)\n",
      "k=93   train_err 39.7% (+: 66.8%)   dev_err 44.5% (+: 67.9%)\n",
      "k=95   train_err 39.6% (+: 66.8%)   dev_err 43.3% (+: 67.7%)\n",
      "k=97   train_err 39.1% (+: 67.4%)   dev_err 43.8% (+: 68.0%)\n",
      "k=99   train_err 39.3% (+: 66.9%)   dev_err 43.3% (+: 66.9%)\n",
      "\n",
      "Best dev error rate is 40.3, when k = 9\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.1.5",
   "id": "bc02e42ffcb97e42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:58:19.894975Z",
     "start_time": "2024-12-03T06:58:19.804527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_predictions = best_native_model.predict(get_embeddings(test_data, wv))\n",
    "\n",
    "test_data_copy = test_data.copy()\n",
    "test_data_copy['target'] = test_predictions\n",
    "\n",
    "test_data_copy.to_csv('test_part2.predicted.csv', index=False)"
   ],
   "id": "6685bd0b6c1cf132",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2 Reimplement Perceptron\n",
    "#### 2.2.1"
   ],
   "id": "dcb248cf63e92939"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:58:21.527806Z",
     "start_time": "2024-12-03T06:58:19.900709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_rate = (0, 101)\n",
    "weights = np.zeros(wv.vector_size)\n",
    "bias = 0\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    train_predictions = np.empty(len(train_data), dtype=str)\n",
    "    dev_predictions = np.empty(len(dev_data), dtype=str)\n",
    "\n",
    "    for i, embedding in enumerate(train_embeddings):\n",
    "        prediction = np.dot(weights, embedding) + bias\n",
    "        label = 1 if train_data.iloc[i]['target'] == \"+\" else -1\n",
    "\n",
    "        if label * prediction <= 0:\n",
    "            weights += label * embedding\n",
    "            bias += label\n",
    "\n",
    "    for i, embedding in enumerate(train_embeddings):\n",
    "        prediction = np.dot(weights, embedding) + bias\n",
    "        label = '+' if prediction > 0 else '-'\n",
    "        train_predictions[i] = label\n",
    "\n",
    "    train_error_rate = (1 - accuracy_score(train_data['target'], train_predictions)) * 100\n",
    "    train_positive_rate = np.mean(train_predictions == \"+\") * 100\n",
    "\n",
    "    for i, embedding in enumerate(dev_embeddings):\n",
    "        prediction = np.dot(weights, embedding) + bias\n",
    "        label = '+' if prediction > 0 else '-'\n",
    "        dev_predictions[i] = label\n",
    "\n",
    "    dev_error_rate = (1 - accuracy_score(dev_data['target'], dev_predictions)) * 100\n",
    "    dev_positive_rate = np.mean(dev_predictions == \"+\") * 100\n",
    "\n",
    "    if dev_error_rate < best_rate[1]:\n",
    "        best_rate = (epoch, dev_error_rate)\n",
    "\n",
    "    print(f\"Epoch={epoch}   train_err {train_error_rate:.1f}% (+: {train_positive_rate:.1f}%)   dev_err {dev_error_rate:.1f}% (+: {dev_positive_rate:.1f}%)\")\n",
    "\n",
    "print(f\"\\nBest dev error rate is {best_rate[1]:.1f}, when epoch = {best_rate[0]}\")"
   ],
   "id": "87b0c3f2f0467c4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=1   train_err 27.8% (+: 31.1%)   dev_err 32.5% (+: 28.5%)\n",
      "Epoch=2   train_err 30.2% (+: 24.3%)   dev_err 36.0% (+: 21.4%)\n",
      "Epoch=3   train_err 35.5% (+: 16.2%)   dev_err 39.2% (+: 15.0%)\n",
      "Epoch=4   train_err 37.0% (+: 14.2%)   dev_err 41.4% (+: 12.2%)\n",
      "Epoch=5   train_err 27.9% (+: 28.5%)   dev_err 33.7% (+: 24.9%)\n",
      "Epoch=6   train_err 25.2% (+: 35.6%)   dev_err 31.3% (+: 32.3%)\n",
      "Epoch=7   train_err 31.4% (+: 22.3%)   dev_err 36.2% (+: 19.6%)\n",
      "Epoch=8   train_err 34.6% (+: 17.7%)   dev_err 39.1% (+: 15.7%)\n",
      "Epoch=9   train_err 38.0% (+: 13.4%)   dev_err 41.8% (+: 11.8%)\n",
      "Epoch=10   train_err 35.0% (+: 17.4%)   dev_err 39.0% (+: 16.0%)\n",
      "\n",
      "Best dev error rate is 31.3, when epoch = 6\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.2.2",
   "id": "fd22775b5bc750d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T07:00:46.101801Z",
     "start_time": "2024-12-03T07:00:44.438070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_avg_perceptron(train_embeddings, dev_embeddings):\n",
    "    best_rate = (0, 101)\n",
    "    weights = np.zeros(wv.vector_size)\n",
    "    bias = 0\n",
    "    total_weights_updates = np.zeros(wv.vector_size)\n",
    "    total_bias_updates = 0\n",
    "    total_updates = 0\n",
    "\n",
    "    for epoch in range(1, 11):\n",
    "        train_predictions = np.empty(len(train_data), dtype=str)\n",
    "        dev_predictions = np.empty(len(dev_data), dtype=str)\n",
    "\n",
    "        for i, embedding in enumerate(train_embeddings):\n",
    "            prediction = np.dot(weights, embedding) + bias\n",
    "            label = 1 if train_data.iloc[i]['target'] == \"+\" else -1\n",
    "\n",
    "            if label * prediction <= 0:\n",
    "                weights += label * embedding\n",
    "                bias += label\n",
    "                total_weights_updates += total_updates * embedding * label\n",
    "                total_bias_updates += total_updates * label\n",
    "\n",
    "            total_updates += 1\n",
    "\n",
    "        avg_weights = weights - (total_weights_updates / total_updates)\n",
    "        avg_bias = bias - (total_bias_updates / total_updates)\n",
    "\n",
    "        for i, embedding in enumerate(train_embeddings):\n",
    "            prediction = np.dot(avg_weights, embedding) + avg_bias\n",
    "            label = '+' if prediction > 0 else '-'\n",
    "            train_predictions[i] = label\n",
    "\n",
    "        train_error_rate = (1 - accuracy_score(train_data['target'], train_predictions)) * 100\n",
    "        train_positive_rate = np.mean(train_predictions == \"+\") * 100\n",
    "\n",
    "        for i, embedding in enumerate(dev_embeddings):\n",
    "            prediction = np.dot(avg_weights, embedding) + avg_bias\n",
    "            label = '+' if prediction > 0 else '-'\n",
    "            dev_predictions[i] = label\n",
    "\n",
    "        dev_error_rate = (1 - accuracy_score(dev_data['target'], dev_predictions)) * 100\n",
    "        dev_positive_rate = np.mean(dev_predictions == \"+\") * 100\n",
    "\n",
    "        if dev_error_rate < best_rate[1]:\n",
    "            best_rate = (epoch, dev_error_rate)\n",
    "\n",
    "        print(f\"Epoch={epoch}   train_err {train_error_rate:.1f}% (+: {train_positive_rate:.1f}%)   dev_err {dev_error_rate:.1f}% (+: {dev_positive_rate:.1f}%)\")\n",
    "\n",
    "    print(f\"\\nBest dev error rate is {best_rate[1]:.1f}, when epoch = {best_rate[0]}\")\n",
    "\n",
    "    return (avg_weights, avg_bias)\n",
    "\n",
    "avg_perceptron_model = train_avg_perceptron(train_embeddings, dev_embeddings)"
   ],
   "id": "f208cb93751af5d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=1   train_err 21.6% (+: 48.8%)   dev_err 25.4% (+: 49.2%)\n",
      "Epoch=2   train_err 21.1% (+: 48.9%)   dev_err 25.3% (+: 48.3%)\n",
      "Epoch=3   train_err 20.9% (+: 48.8%)   dev_err 25.2% (+: 48.6%)\n",
      "Epoch=4   train_err 20.9% (+: 48.6%)   dev_err 25.0% (+: 47.4%)\n",
      "Epoch=5   train_err 20.8% (+: 48.7%)   dev_err 24.2% (+: 47.8%)\n",
      "Epoch=6   train_err 20.9% (+: 48.6%)   dev_err 24.3% (+: 47.9%)\n",
      "Epoch=7   train_err 20.9% (+: 48.8%)   dev_err 24.5% (+: 47.7%)\n",
      "Epoch=8   train_err 21.0% (+: 48.9%)   dev_err 24.4% (+: 48.0%)\n",
      "Epoch=9   train_err 20.8% (+: 48.9%)   dev_err 24.3% (+: 48.1%)\n",
      "Epoch=10   train_err 20.8% (+: 49.0%)   dev_err 24.6% (+: 47.8%)\n",
      "\n",
      "Best dev error rate is 24.2, when epoch = 5\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.2.4",
   "id": "3a607a1eab0b36d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T07:01:12.614502Z",
     "start_time": "2024-12-03T07:01:10.703002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_embeddings_pruned = get_embeddings_pruned(train_data, wv, 1)\n",
    "dev_embeddings_pruned = get_embeddings_pruned(dev_data, wv, 1)\n",
    "\n",
    "avg_perceptron_pruned_model = train_avg_perceptron(train_embeddings_pruned, dev_embeddings_pruned)"
   ],
   "id": "97cd255b10336f1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=1   train_err 22.4% (+: 49.0%)   dev_err 28.1% (+: 47.5%)\n",
      "Epoch=2   train_err 21.9% (+: 49.3%)   dev_err 27.3% (+: 46.7%)\n",
      "Epoch=3   train_err 21.8% (+: 49.2%)   dev_err 27.4% (+: 47.2%)\n",
      "Epoch=4   train_err 21.6% (+: 49.2%)   dev_err 26.8% (+: 47.2%)\n",
      "Epoch=5   train_err 21.7% (+: 49.1%)   dev_err 26.8% (+: 47.2%)\n",
      "Epoch=6   train_err 21.7% (+: 49.0%)   dev_err 27.0% (+: 46.6%)\n",
      "Epoch=7   train_err 21.8% (+: 49.1%)   dev_err 26.9% (+: 47.1%)\n",
      "Epoch=8   train_err 21.7% (+: 49.1%)   dev_err 26.6% (+: 47.2%)\n",
      "Epoch=9   train_err 21.8% (+: 49.1%)   dev_err 26.7% (+: 47.5%)\n",
      "Epoch=10   train_err 21.8% (+: 49.3%)   dev_err 26.7% (+: 47.3%)\n",
      "\n",
      "Best dev error rate is 26.6, when epoch = 8\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.2.5",
   "id": "98de56b4abcf0a44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T07:11:52.747091Z",
     "start_time": "2024-12-03T07:11:52.608283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "one_hot_dev_predictions = best_native_model.predict(get_embeddings(dev_data, wv))\n",
    "perceptron_predictions = np.empty(len(dev_data), dtype=str)\n",
    "\n",
    "for i, embedding in enumerate(get_embeddings(dev_data, wv)):\n",
    "    prediction = np.dot(avg_perceptron_model[0], embedding) + avg_perceptron_model[1]\n",
    "    label = '+' if prediction > 0 else '-'\n",
    "    perceptron_predictions[i] = label\n",
    "\n",
    "for i, label in enumerate(dev_data['target']):\n",
    "    if label == perceptron_predictions[i] and label != one_hot_dev_predictions[i]:\n",
    "        print(dev_data.iloc[i][\"sentence\"])\n",
    "        print(f'Word2vec guess {perceptron_predictions[i]} (correct)')\n",
    "        print(f'Word2vec guess {one_hot_dev_predictions[i]} (incorrect)\\n')"
   ],
   "id": "9cc63b85330f55f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a real audience pleaser that will strike a chord with anyone who 's ever waited in a doctor 's office , emergency room , hospital bed or insurance company office\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "get out your pooper scoopers\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "you 've already seen city by the sea under a variety of titles , but it 's worth yet another visit\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "if signs is a good film , and it is , the essence of a great one is in there somewhere\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "although largely a heavy handed indictment of parental failings and the indifference of spanish social workers and legal system towards child abuse , the film retains ambiguities that make it well worth watching\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "suffers from unlikable characters and a self conscious sense of its own quirky hipness\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "god bless crudup and his aversion to taking the easy hollywood road and cashing in on his movie star gorgeousness\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "one of the worst movies of the year\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "a sustained fest of self congratulation between actor and director that leaves scant place for the viewer\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "this is an exercise not in biography but in hero worship\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "as it turns out , you can go home again\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "rarely has sex on screen been so aggressively anti erotic\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "even if you 've never heard of chaplin , you 'll still be glued to the screen\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "it is hard not to be especially grateful for freedom after a film like this\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "if you thought tom hanks was just an ordinary big screen star , wait until you 've seen him eight stories tall\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "lacks the visual flair and bouncing bravado that characterizes better hip hop clips and is content to recycle images and characters that were already tired 10 years ago\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "a small gem of a movie that defies classification and is as thought provoking as it is funny , scary and sad\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "evokes the style and flash of the double cross that made mamet 's house of games and last fall 's heist so much fun\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "works on some levels and is certainly worth seeing at least once\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "contrasting the original ringu with the current americanized adaptation is akin to comparing the evil dead with evil dead ii\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "the action sequences are fun and reminiscent of combat scenes from the star wars series\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "the messy emotions raging throughout this three hour effort are instantly recognizable , allowing the film to paradoxically feel familiar and foreign at the same time\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "a singularly off putting romantic comedy\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "the leads we are given here are simply too bland to be interesting\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "on guard ! wo n't be placed in the pantheon of the best of the swashbucklers but it is a whole lot of fun and you get to see the one of the world 's best actors , daniel auteuil , have a whale of a good time\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "visually exciting sci fi film which suffers from a lackluster screenplay\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "it 's funny , as the old saying goes , because it 's true\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "degenerates into hogwash\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "for dance completists only\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "the film becomes an overwhelming pleasure , and you find yourself rooting for gai 's character to avoid the fate that has befallen every other carmen before her\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "like all great films about a life you never knew existed , it offers much to absorb and even more to think about after the final frame\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "a preachy parable stylized with a touch of john woo bullet ballet\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "rather less than the sum of its underventilated p re fils confrontations\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "a bodice ripper for intellectuals\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "graphic sex may be what 's attracting audiences to unfaithful , but gripping performances by lane and gere are what will keep them awake\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "a reworking of die hard and cliffhanger but it 's nowhere near as exciting as either\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "it thankfully goes easy on the reel real world dichotomy that jaglom pursued with such enervating determination in venice venice\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "if you 've the patience , there are great rewards here\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "fresnadillo has something serious to say about the ways in which extravagant chance can distort our perspective and throw us off the path of good sense\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "though the film never veers from its comic course , its unintentional parallels might inadvertently evoke memories and emotions which are anything but humorous\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "the movie 's vision of a white american zealously spreading a puritanical brand of christianity to south seas islanders is one only a true believer could relish\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "brosnan is more feral in this film than i 've seen him before and halle berry does her best to keep up with him\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "the footage of the rappers at play and the prison interview with suge knight are just two of the elements that will grab you\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "frailty offers chills much like those that you get when sitting around a campfire around midnight , telling creepy stories to give each other the willies and , there 's no way you wo n't be talking about the film once you exit the theater\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "a dreadful day in irish history is given passionate , if somewhat flawed , treatment\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "just watch bettany strut his stuff you 'll know a star when you see one\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "all the small moments and flashbacks do n't add up to much more than trite observations on the human condition\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "the real star of this movie is the score , as in the songs translate well to film , and it 's really well directed\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "as averse as i usually am to feel good , follow your dream hollywood fantasies , this one got to me\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "there are problems with this film that even 3 oscar winners ca n't overcome , but it 's a nice girl buddy movie once it gets rock n rolling\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "like most of jaglom 's films , some of it is honestly affecting , but more of it seems contrived and secondhand\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "it 's hard to believe that a relationship like holly and marina 's could survive the hothouse emotions of teendom , and its longevity gets more inexplicable as the characterizations turn more crassly reductive\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "shows moments of promise but ultimately succumbs to cliches and pat storytelling\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "dog soldiers does n't transcend genre it embraces it , energizes it and takes big bloody chomps out of it\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "except for paymer as the boss who ultimately expresses empathy for bartleby 's pain , the performances are so stylized as to be drained of human emotion\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "gives everyone something to shout about\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "shyamalan offers copious hints along the way myriad signs , if you will that beneath the familiar , funny surface is a far bigger , far more meaningful story than one in which little green men come to earth for harvesting purposes\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "it 's sweet it 's funny it wears its heart on the sleeve of its gaudy hawaiian shirt and , thanks to the presence of ` the king , ' it also rocks\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "pretend like your sat scores are below 120 and you might not notice the flaws\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "from blushing to gushing imamura squirts the screen in warm water under a red bridge '\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "ice age is the first computer generated feature cartoon to feel like other movies , and that makes for some glacial pacing early on\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "rarely has a film 's title served such dire warning\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "the chateau is less concerned with cultural and political issues than doting on its eccentric characters\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "the cast keeps this pretty watchable , and casting mick jagger as director of the escort service was inspired\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "she 's as rude and profane as ever , always hilarious and , most of the time , absolutely right in her stinging social observations\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "formula 51 promises a new kind of high but delivers the same old bad trip\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "for a movie about the power of poetry and passion , there is precious little of either\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "more busy than exciting , more frantic than involving , more chaotic than entertaining\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "this is one of those war movies that focuses on human interaction rather than battle and action sequences and it 's all the stronger because of it\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "with all the sympathy , empathy and pity fogging up the screen his secret life enters the land of unintentional melodrama and tiresome love triangles\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "one of those movies that catches you up in something bigger than yourself , namely , an archetypal desire to enjoy good trash every now and then\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "hilarious musical comedy though stymied by accents thick as mud\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "in the end there is one word that best describes this film honest\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "what makes esther kahn so demanding is that it progresses in such a low key manner that it risks monotony but it 's worth the concentration\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "quiet , adult and just about more stately than any contemporary movie this year a true study , a film with a questioning heart and mind that is n't afraid to admit it does n't have all the answers\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "the movie 's captivating details are all in the performances , from foreman 's barking mad taylor to thewlis 's smoothly sinister freddie and bettany mcdowell 's hard eyed gangster\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "chris columbus ' sequel is faster , livelier and a good deal funnier than his original\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "you have enough finely tuned acting to compensate for the movie 's failings\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "any movie that makes hard work seem heroic deserves a look\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "continually challenges perceptions of guilt and innocence , of good guys and bad , and asks us whether a noble end can justify evil means\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "like mike is a slight and uninventive movie like the exalted michael jordan referred to in the title , many can aspire but none can equal\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "miyazaki 's nonstop images are so stunning , and his imagination so vivid , that the only possible complaint you could have about spirited away is that there is no rest period , no timeout\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "its screenplay serves as auto critique , and its clumsiness as its own most damning censure\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "knockaround guys plays like a student film by two guys who desperately want to be quentin tarantino when they grow up but they lack their idol 's energy and passion for detail\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "as david letterman and the onion have proven , the worst of tragedies can be fertile sources of humor , but lawrence has only a fleeting grasp of how to develop them\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "digs beyond the usual portrayals of good kids and bad seeds to reveal a more ambivalent set of characters and motivations\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "y tu mam tambi n is hilariously , gloriously alive , and quite often hotter than georgia asphalt\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "he 's the scariest guy you 'll see all summer\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "it 's absolutely amazing how first time director kevin donovan managed to find something new to add to the canon of chan make chan 's action sequences boring\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "if the material is slight and admittedly manipulative , jacquot preserves tosca 's intoxicating ardor through his use of the camera\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "dismally dull sci fi comedy\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "wallace directs with such patronising reverence , it turns the stomach\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "sandra bullock and hugh grant make a great team , but this predictable romantic comedy should get a pink slip\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "secretary is owned by its costars , spader and gyllenhaal maggie g makes an amazing breakthrough in her first starring role and eats up the screen\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "instead of using george and lucy 's most obvious differences to ignite sparks , lawrence desperately looks elsewhere , seizing on george 's haplessness and lucy 's personality tics\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "it 's like a big chill reunion of the baader meinhof gang , only these guys are more harmless pranksters than political activists\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "if the very concept makes you nervous you 'll have an idea of the film 's creepy , scary effectiveness\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "the story is predictable , the jokes are typical sandler fare , and the romance with ryder is puzzling\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "do n't wait to see this terrific film with your kids if you do n't have kids borrow some\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "raimi crafted a complicated hero who is a welcome relief from the usual two dimensional offerings\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "if it 's not entirely memorable , the movie is certainly easy to watch\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "for almost the first two thirds of martin scorsese 's 168 minute gangs of new york , i was entranced\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "by applying definition to both sides of the man , the picture realizes a fullness that does not negate the subject\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "the following things are not at all entertaining the bad sound , the lack of climax and , worst of all , watching seinfeld ( who is also one of the film 's producers ) do everything he can to look like a good guy\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "there has been a string of ensemble cast romances recently but peter mattei 's love in the time of money sets itself apart by forming a chain of relationships that come full circle to end on a positive ( if tragic ) note\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "puts to rest any thought that the german film industry can not make a delightful comedy centering on food\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "if you like an extreme action packed film with a hint of humor , then triple x marks the spot\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "it has a dashing and resourceful hero a lisping , reptilian villain big fights big hair lavish period scenery and a story just complicated enough to let you bask in your own cleverness as you figure it out\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "scotland , pa is entirely too straight faced to transcend its clever concept\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "blisteringly rude , scarily funny , sorrowfully sympathetic to the damage it surveys , the film has in kieran culkin a pitch perfect holden\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "dodgy mixture of cutesy romance , dark satire and murder mystery\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "exposing the ways we fool ourselves is one hour photo 's real strength\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "while hollywood ending has its share of belly laughs ( including a knockout of a closing line ) , the movie winds up feeling like a great missed opportunity\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "screenwriter dan schneider and director shawn levy substitute volume and primary colors for humor and bite\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "it seems impossible that an epic four hour indian musical about a cricket game could be this good , but it is\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "a live action cartoon , a fast moving and cheerfully simplistic 88 minutes of exaggerated action put together with the preteen boy in mind\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "a perfectly competent and often imaginative film that lacks what little lilo stitch had in spades charisma\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "all the characters are clinically depressed and have abandoned their slim hopes and dreams\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "upsetting and thought provoking , the film has an odd purity that does n't bring you into the characters so much as it has you study them\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n",
      "a distinctly mixed bag , the occasional bursts of sharp writing alternating with lots of sloppiness and the obligatory moments of sentimental ooze\n",
      "Word2vec guess - (correct)\n",
      "Word2vec guess + (incorrect)\n",
      "\n",
      "it 's never laugh out loud funny , but it is frequently amusing\n",
      "Word2vec guess + (correct)\n",
      "Word2vec guess - (incorrect)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.2.6",
   "id": "7c6e37362eb4d527"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T07:20:59.660232Z",
     "start_time": "2024-12-03T07:20:59.622258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = np.empty(len(test_data), dtype=str)\n",
    "\n",
    "for i, embedding in enumerate(get_embeddings(test_data, wv)):\n",
    "    prediction = np.dot(avg_perceptron_model[0], embedding) + avg_perceptron_model[1]\n",
    "    label = '+' if prediction > 0 else '-'\n",
    "    predictions[i] = label\n",
    "\n",
    "test_data_copy = test_data.copy()\n",
    "test_data_copy['target'] = predictions\n",
    "\n",
    "test_data_copy.to_csv('test_part2_perceptron.predicted.csv', index=False)"
   ],
   "id": "cb29dccbcd5852fd",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T07:21:03.639762Z",
     "start_time": "2024-12-03T07:21:03.594972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = np.empty(len(test_data), dtype=str)\n",
    "\n",
    "for i, embedding in enumerate(get_embeddings(test_data, wv)):\n",
    "    prediction = np.dot(avg_perceptron_pruned_model[0], embedding) + avg_perceptron_pruned_model[1]\n",
    "    label = '+' if prediction > 0 else '-'\n",
    "    predictions[i] = label\n",
    "\n",
    "test_data_copy = test_data.copy()\n",
    "test_data_copy['target'] = predictions\n",
    "\n",
    "test_data_copy.to_csv('test_part2_perceptron_pruned.predicted.csv', index=False)"
   ],
   "id": "15f0e86e6815bd60",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3 Try some other learning algorithms with sklearn",
   "id": "a13e2c021131c489"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T07:43:58.704422Z",
     "start_time": "2024-12-03T07:43:51.938515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "classifier.fit(train_embeddings, train_data['target'].apply(lambda x: 1 if x == \"+\" else -1))\n",
    "\n",
    "train_predictions = classifier.predict(train_embeddings)\n",
    "train_labels_pred = [\"+\" if label == 1 else \"-\" for label in train_predictions]\n",
    "\n",
    "train_error_rate = (1 - accuracy_score(train_data['target'], train_labels_pred)) * 100\n",
    "train_positive_rate = train_labels_pred.count(\"+\") / len(train_labels_pred) * 100\n",
    "\n",
    "dev_predictions = classifier.predict(dev_embeddings)\n",
    "dev_labels_pred = [\"+\" if label == 1 else \"-\" for label in dev_predictions]\n",
    "\n",
    "dev_error_rate = (1 - accuracy_score(dev_data['target'], dev_labels_pred)) * 100\n",
    "dev_positive_rate = dev_labels_pred.count(\"+\") / len(dev_labels_pred) * 100\n",
    "\n",
    "print(f\"train_err {train_error_rate:.1f}% (+: {train_positive_rate:.1f}%)   dev_err {dev_error_rate:.1f}% (+: {dev_positive_rate:.1f}%)\")\n",
    "print(f\"Runtime: {time.time() - start_time:.2f} sec\")"
   ],
   "id": "90e3b997bfd90824",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_err 20.4% (+: 47.9%)   dev_err 23.7% (+: 47.3%)\n",
      "Runtime: 6.76 sec\n"
     ]
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:03:37.996139Z",
     "start_time": "2024-12-03T08:03:37.657895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_predictions = classifier.predict(get_embeddings(test_data, wv))\n",
    "test_labels_pred = [\"+\" if label == 1 else \"-\" for label in test_predictions]\n",
    "\n",
    "test_data_copy = test_data.copy()\n",
    "test_data_copy['target'] = test_labels_pred\n",
    "\n",
    "test_data_copy.to_csv(\"test_part3.predicted.csv\", index=False)\n"
   ],
   "id": "a60832b67146a607",
   "outputs": [],
   "execution_count": 120
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
